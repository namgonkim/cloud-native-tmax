# 클라우드 개발자 양성과정

## 상용 클라우드를 이용한 어플리케이션 배포
[소스코드](https://github.com/namgonkim/msa-ecommerce-tmax)
* 토이 프로젝트를 통한 msa 어플리케이션 실습
    - 데이터 동기화를 위한 kafka 활용
        - kafka적용: Orders -> Catalogs Service
        - kafka적용: Multiple Orders Service


## 데이터 동기화
### Orders -> Catalogs

```
order --send--> Topic(Kafka) ---> catalog
수량정보가 topic으로 넘어가 catalogs 내 수량을 업데이트
UPDATE qty = qty - topic.data.qty
```

### Multiple Orders Service
* Orders Service 2개 이상 기동
    - users의 요청 분산 처리
    - orders 데이터도 분산 저장 -> 동기화 문제
* Orders Service에 요청 된 주문 정보를 DB가 아니라 Kafka Topic으로 전송
* Kafka Topic에 설정 된 Kafka Sink Connect를 사용해 단일 DB에 저장 -> 데이터 동기화

### 동기화 과정 시 발생할 수 있는 문제
* Transaction을 통해 데이터 locking하는 방안
* local -> aws rds
    - topic으로 보낼때 JdbcSinkConnector가 데이터의 스키마와 포맷을 지정
    - 싱크 커넥트가 이해할 수 있는 형태의 포맷이 핵심.
    - topic에 있는 database를 갖고 jdbc 싱크 커넥터를 갖고 데이터베이스를 저장할 수 없다.
> 주문 데이터 포맷을 kafka topic으로 들어가기 알맞은 포맷으로 변환해 주어야 한다.

### orders service producer에서 발생(발행)하기 위한 메세지 포맷
```json
// POST /order-service/{user_id}/orders
{
    "schema":{
        "type":"struct",
        "fields":[
            {"type":"string","optional":false,"field":"product_id"},
            {"type":"int32","optional":false,"field":"qty"},
            {"type":"int32","optional":false,"field":"unit_price"},
            {"type":"string","optional":false,"field":"user_id"},
            {"type":"int32","optional":false,"field":"total_price"}
            {"type":"string","optional":false,"field":"order_id"},
        ],
        "optional":false,
        "name":"orders"
    },
    "payload":{
        "product_id" : "CATALOG-002",
        "qty" : 30,
        "unit_price" : 1100,
        "user_id" : "d75781b8-0358-45d2-93d8-7399325121b0",
        "total_price" : 33000,
        "order_id" : "88bfd35f-0ee6-47a3-bf12-9410e49721da"
    }
}
```
#### java object -> json string value
* @Builder와 @AllArgsConstructor 어노테이션을 이용해 payload, schema, fields, orderDto 생성
* objectMapper.writeValueAsString() 함수 활용해 자바 객체를 json string으로 변경
